2020-10-04 22:33:12.159711 / Namespace(activation='ReLU', atoms=[0.0, 25564.669921875], batch_size=4096, comet=True, data='lalonde_cps1', dataroot='/home/mila/r/raghupas/causal-benchmark/datasets', dim_h=64, dist='SigmoidFlow', dist_args=['ndim=32', 'base_distribution=normal'], early_stop=True, eval=True, grad_norm=inf, ignore_w=False, lr=0.001, n_hidden_layers=2, num_epochs=2000, num_univariate_tests=100, overwrite_reload='', saveroot='./experiments/sigmoidflow_lalonde_cps1/dist_argsndim=32+base_distribution=normal-n_hidden_layers2-dim_h64-lr0.001-w_transformStandardize', seed=123, test_prop=0.4, test_size=None, train=True, train_prop=0.5, val_prop=0.1, w_transform='Standardize', y_transform='Normalize') 
2020-10-04 22:33:12.163561 / getting data: lalonde_cps1 
2020-10-04 22:33:39.148649 / comet url: https://www.comet.ml/sunandr/causal-benchmark/87899cabdbe440c581b1cc44966b2ef8 
2020-10-04 22:33:39.151041 / ate: None 
2020-10-04 22:33:39.153250 / <models.distributions.distributions.MixedDistribution object at 0x7f0e271252d0> 
2020-10-04 22:33:39.155796 / {'n_hidden_layers': 2, 'dim_h': 64, 'activation': ReLU()} 
2020-10-04 22:33:39.158399 / {'batch_size': 4096, 'lr': 0.001, 'num_epochs': 2000, 'verbose': True, 'print_every_iters': 100, 'optim': <class 'torch.optim.adam.Adam'>, 'eval_every': 100, 'plot_every': 1000, 'p_every': 100, 'optim_args': {}} 
2020-10-04 22:34:09.085812 / Iteration 100: 0.034684449434280396 0.4249339699745178 
2020-10-04 22:34:09.209306 / Iteration 100 valid loss 0.45042869448661804 
2020-10-04 22:34:09.211407 / saving best-val-loss model 
2020-10-04 22:34:38.285023 / Iteration 200: 0.03364164009690285 0.3587171137332916 
2020-10-04 22:34:38.322406 / Iteration 200 valid loss 0.35732877254486084 
2020-10-04 22:34:38.324141 / saving best-val-loss model 
2020-10-04 22:35:06.887140 / Iteration 300: 0.023618867620825768 0.3131207823753357 
2020-10-04 22:35:06.977560 / Iteration 300 valid loss 0.3364490270614624 
2020-10-04 22:35:06.980002 / saving best-val-loss model 
2020-10-04 22:35:37.079429 / Iteration 400: 0.026930134743452072 0.28416797518730164 
2020-10-04 22:35:37.182120 / Iteration 400 valid loss 0.32778286933898926 
2020-10-04 22:35:37.191260 / saving best-val-loss model 
2020-10-04 22:36:05.538237 / Iteration 500: 0.028293415904045105 0.29667845368385315 
2020-10-04 22:36:05.603981 / Iteration 500 valid loss 0.31507906317710876 
2020-10-04 22:36:05.605837 / saving best-val-loss model 
2020-10-04 22:36:34.806496 / Iteration 600: 0.024656059220433235 0.2539708912372589 
2020-10-04 22:36:34.850100 / Iteration 600 valid loss 0.3100975751876831 
2020-10-04 22:36:34.852107 / saving best-val-loss model 
2020-10-04 22:37:03.988302 / Iteration 700: 0.02862788550555706 0.27240315079689026 
2020-10-04 22:37:04.031576 / Iteration 700 valid loss 0.31057828664779663 
2020-10-04 22:37:34.528140 / Iteration 800: 0.02751685306429863 0.2921188473701477 
2020-10-04 22:37:34.603845 / Iteration 800 valid loss 0.3140597343444824 
2020-10-04 22:38:03.699244 / Iteration 900: 0.021477723494172096 0.2561573088169098 
2020-10-04 22:38:03.737650 / Iteration 900 valid loss 0.32138484716415405 
2020-10-04 22:38:33.308799 / Iteration 1000: 0.02626125141978264 0.25515496730804443 
2020-10-04 22:38:33.367340 / Iteration 1000 valid loss 0.3215816915035248 
2020-10-04 22:39:12.061218 / Iteration 1100: 0.02510985918343067 0.23746882379055023 
2020-10-04 22:39:12.124485 / Iteration 1100 valid loss 0.32443439960479736 
2020-10-04 22:39:41.553464 / Iteration 1200: 0.023148689419031143 0.24768993258476257 
2020-10-04 22:39:41.598893 / Iteration 1200 valid loss 0.33360016345977783 
2020-10-04 22:40:12.522797 / Iteration 1300: 0.019677994772791862 0.23985101282596588 
2020-10-04 22:40:12.583822 / Iteration 1300 valid loss 0.33704906702041626 
2020-10-04 22:40:41.919072 / Iteration 1400: 0.018376732245087624 0.2380126565694809 
2020-10-04 22:40:41.973844 / Iteration 1400 valid loss 0.3386659026145935 
2020-10-04 22:41:11.571952 / Iteration 1500: 0.02011408843100071 0.2245500236749649 
2020-10-04 22:41:11.625385 / Iteration 1500 valid loss 0.34577682614326477 
2020-10-04 22:41:40.347998 / Iteration 1600: 0.01946079730987549 0.25153371691703796 
2020-10-04 22:41:40.403403 / Iteration 1600 valid loss 0.3493845760822296 
2020-10-04 22:42:09.583231 / Iteration 1700: 0.020719263702630997 0.22474493086338043 
2020-10-04 22:42:09.673380 / Iteration 1700 valid loss 0.35843217372894287 
2020-10-04 22:42:39.315259 / Iteration 1800: 0.026949862018227577 0.20834454894065857 
2020-10-04 22:42:39.378267 / Iteration 1800 valid loss 0.3611961007118225 
2020-10-04 22:43:09.266672 / Iteration 1900: 0.024480581283569336 0.24185363948345184 
2020-10-04 22:43:09.340526 / Iteration 1900 valid loss 0.3666849732398987 
2020-10-04 22:43:38.183534 / Iteration 2000: 0.022503694519400597 0.21198509633541107 
2020-10-04 22:43:38.247445 / Iteration 2000 valid loss 0.3738391697406769 
2020-10-04 22:44:16.345583 / Iteration 2100: 0.02424073964357376 0.16459815204143524 
2020-10-04 22:44:16.395054 / Iteration 2100 valid loss 0.38988354802131653 
2020-10-04 22:44:45.977353 / Iteration 2200: 0.022393707185983658 0.2019946277141571 
2020-10-04 22:44:46.076784 / Iteration 2200 valid loss 0.38600969314575195 
2020-10-04 22:45:15.614259 / Iteration 2300: 0.016440177336335182 0.20100995898246765 
2020-10-04 22:45:15.725131 / Iteration 2300 valid loss 0.3915056586265564 
2020-10-04 22:45:45.117572 / Iteration 2400: 0.01917504332959652 0.2116294652223587 
2020-10-04 22:45:45.186870 / Iteration 2400 valid loss 0.4022426903247833 
2020-10-04 22:46:14.900230 / Iteration 2500: 0.016903428360819817 0.1736781895160675 
2020-10-04 22:46:15.022033 / Iteration 2500 valid loss 0.41486573219299316 
2020-10-04 22:46:44.629713 / Iteration 2600: 0.016532592475414276 0.18692360818386078 
2020-10-04 22:46:44.694054 / Iteration 2600 valid loss 0.4111977815628052 
2020-10-04 22:47:13.206803 / Iteration 2700: 0.017445247620344162 0.19480815529823303 
2020-10-04 22:47:13.269510 / Iteration 2700 valid loss 0.4328794479370117 
2020-10-04 22:47:38.199989 / Iteration 2800: 0.017717532813549042 0.19472014904022217 
2020-10-04 22:47:38.250955 / Iteration 2800 valid loss 0.4296596348285675 
2020-10-04 22:48:04.918014 / Iteration 2900: 0.01749223656952381 0.19056104123592377 
2020-10-04 22:48:04.959754 / Iteration 2900 valid loss 0.44263002276420593 
2020-10-04 22:48:31.814055 / Iteration 3000: 0.014481505379080772 0.18036551773548126 
2020-10-04 22:48:31.858356 / Iteration 3000 valid loss 0.4532642960548401 
2020-10-04 22:49:09.722117 / Iteration 3100: 0.015200162306427956 0.18266722559928894 
2020-10-04 22:49:09.796330 / Iteration 3100 valid loss 0.45810651779174805 
2020-10-04 22:49:41.316083 / Iteration 3200: 0.015735264867544174 0.19616757333278656 
2020-10-04 22:49:41.368598 / Iteration 3200 valid loss 0.482028603553772 
2020-10-04 22:50:12.266121 / Iteration 3300: 0.01529606245458126 0.18643558025360107 
2020-10-04 22:50:12.313449 / Iteration 3300 valid loss 0.48249974846839905 
2020-10-04 22:50:42.819124 / Iteration 3400: 0.012477315030992031 0.17184992134571075 
2020-10-04 22:50:42.872969 / Iteration 3400 valid loss 0.4917740225791931 
2020-10-04 22:51:15.414225 / Iteration 3500: 0.01240991335362196 0.16314131021499634 
2020-10-04 22:51:15.461882 / Iteration 3500 valid loss 0.46850156784057617 
2020-10-04 22:51:45.427996 / Iteration 3600: 0.016168013215065002 0.1601119190454483 
2020-10-04 22:51:45.486384 / Iteration 3600 valid loss 0.5035642981529236 
2020-10-04 22:52:15.735293 / Iteration 3700: 0.014769439585506916 0.15962930023670197 
2020-10-04 22:52:15.798839 / Iteration 3700 valid loss 0.507338285446167 
2020-10-04 22:52:47.143764 / Iteration 3800: 0.013410622254014015 0.14897845685482025 
2020-10-04 22:52:47.181436 / Iteration 3800 valid loss 0.5188801288604736 
2020-10-04 22:53:18.849585 / Iteration 3900: 0.010958506725728512 0.15011703968048096 
2020-10-04 22:53:18.908646 / Iteration 3900 valid loss 0.5357000231742859 
2020-10-04 22:53:52.508939 / Iteration 4000: 0.012144849635660648 0.13150238990783691 
2020-10-04 22:53:52.574184 / Iteration 4000 valid loss 0.543834924697876 
2020-10-04 22:57:42.391319 / OrderedDict([('nll', 0.3100975751876831), ('avg_t_pval', 0.9999997343052958), ('avg_y_pval', 0.05215206500986905), ('min_t_pval', 0.9999905252332428), ('min_y_pval', 9.468819536528894e-05), ('q30_t_pval', 0.9999999999998349), ('q30_y_pval', 0.01307749709884245), ('q50_t_pval', 1.0), ('q50_y_pval', 0.03516271919609104), ('ate_exact', -14.259007453918457), ('ate_noisy', -7148.995737304687)]) 
