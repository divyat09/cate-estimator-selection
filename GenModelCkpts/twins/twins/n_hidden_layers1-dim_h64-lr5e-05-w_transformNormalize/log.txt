2020-10-24 21:12:52.735116 / Namespace(activation='ReLU', atoms=[], batch_size=256, comet=True, data='twins', dataroot='/home/mila/r/raghupas/causal-benchmark/datasets', dim_h=64, dist='Bernoulli', dist_args=[], early_stop=True, eval=True, grad_norm=inf, ignore_w=False, lr=5e-05, n_hidden_layers=1, num_epochs=10000, num_univariate_tests=100, overwrite_reload='', patience=2000, saveroot='./experiments/twins/n_hidden_layers1-dim_h64-lr5e-05-w_transformNormalize', seed=123, test_prop=0.4, test_size=None, train=True, train_prop=0.5, val_prop=0.1, w_transform='Normalize', y_transform='Normalize') 
2020-10-24 21:12:52.745151 / getting data: twins 
2020-10-24 21:13:56.872130 / comet url: https://www.comet.ml/sunandr/causal-benchmark/35ff8e0861b64bc5946b624b2146d7fc 
2020-10-24 21:13:56.876397 / ate: -0.02520026702269693 
2020-10-24 21:13:56.880867 / <models.distributions.distributions.Bernoulli object at 0x7f0166f4d290> 
2020-10-24 21:13:56.885722 / {'n_hidden_layers': 1, 'dim_h': 64, 'activation': ReLU()} 
2020-10-24 21:13:56.890434 / {'batch_size': 256, 'lr': 5e-05, 'num_epochs': 10000, 'verbose': True, 'print_every_iters': 100, 'optim': <class 'torch.optim.adam.Adam'>, 'eval_every': 100, 'plot_every': 10000, 'p_every': 1000, 'optim_args': {}} 
2020-10-24 21:13:58.539770 / Iteration 100: 0.6569204330444336 0.6534440517425537 
2020-10-24 21:13:58.588144 / Iteration 100 valid loss 1.305119514465332 
2020-10-24 21:13:58.592947 / saving best-val-loss model 
2020-10-24 21:14:00.076074 / Iteration 200: 0.6410279870033264 0.62569260597229 
2020-10-24 21:14:00.138196 / Iteration 200 valid loss 1.2580022811889648 
2020-10-24 21:14:00.143969 / saving best-val-loss model 
2020-10-24 21:14:01.626544 / Iteration 300: 0.6155509948730469 0.5687509179115295 
2020-10-24 21:14:01.693665 / Iteration 300 valid loss 1.1744801998138428 
2020-10-24 21:14:01.697702 / saving best-val-loss model 
2020-10-24 21:14:03.221194 / Iteration 400: 0.5754901766777039 0.4777352511882782 
2020-10-24 21:14:03.270342 / Iteration 400 valid loss 1.0604764223098755 
2020-10-24 21:14:03.274719 / saving best-val-loss model 
2020-10-24 21:14:04.814287 / Iteration 500: 0.6199337244033813 0.41483792662620544 
2020-10-24 21:14:04.873368 / Iteration 500 valid loss 0.9904848337173462 
2020-10-24 21:14:04.877943 / saving best-val-loss model 
2020-10-24 21:14:06.477860 / Iteration 600: 0.5921931266784668 0.446330726146698 
2020-10-24 21:14:06.550609 / Iteration 600 valid loss 0.9720639586448669 
2020-10-24 21:14:06.555855 / saving best-val-loss model 
2020-10-24 21:14:08.106179 / Iteration 700: 0.516187310218811 0.513983428478241 
2020-10-24 21:14:08.157052 / Iteration 700 valid loss 0.9678376317024231 
2020-10-24 21:14:08.161212 / saving best-val-loss model 
2020-10-24 21:14:09.672271 / Iteration 800: 0.5708298087120056 0.43985679745674133 
2020-10-24 21:14:09.728214 / Iteration 800 valid loss 0.9659079313278198 
2020-10-24 21:14:09.739611 / saving best-val-loss model 
2020-10-24 21:14:11.290752 / Iteration 900: 0.5289455056190491 0.4738067388534546 
2020-10-24 21:14:11.349583 / Iteration 900 valid loss 0.9647561311721802 
2020-10-24 21:14:11.362037 / saving best-val-loss model 
2020-10-24 21:14:13.001140 / Iteration 1000: 0.5753724575042725 0.4664943814277649 
2020-10-24 21:14:13.071186 / Iteration 1000 valid loss 0.9639395475387573 
2020-10-24 21:14:13.075192 / saving best-val-loss model 
2020-10-24 21:14:14.875127 / Iteration 1100: 0.6080216765403748 0.4675803780555725 
2020-10-24 21:14:14.938796 / Iteration 1100 valid loss 0.9626523852348328 
2020-10-24 21:14:14.943231 / saving best-val-loss model 
2020-10-24 21:14:16.525075 / Iteration 1200: 0.6338018774986267 0.5473638772964478 
2020-10-24 21:14:16.579451 / Iteration 1200 valid loss 0.961944043636322 
2020-10-24 21:14:16.591577 / saving best-val-loss model 
2020-10-24 21:14:18.175659 / Iteration 1300: 0.5785269737243652 0.455070436000824 
2020-10-24 21:14:18.216311 / Iteration 1300 valid loss 0.9607098698616028 
2020-10-24 21:14:18.225615 / saving best-val-loss model 
2020-10-24 21:14:19.734923 / Iteration 1400: 0.580623209476471 0.4879723787307739 
2020-10-24 21:14:19.779478 / Iteration 1400 valid loss 0.959734320640564 
2020-10-24 21:14:19.783917 / saving best-val-loss model 
2020-10-24 21:14:21.283391 / Iteration 1500: 0.6026812791824341 0.42256805300712585 
2020-10-24 21:14:21.329702 / Iteration 1500 valid loss 0.9586212038993835 
2020-10-24 21:14:21.337270 / saving best-val-loss model 
2020-10-24 21:14:22.938764 / Iteration 1600: 0.5714253187179565 0.5037962794303894 
2020-10-24 21:14:22.994161 / Iteration 1600 valid loss 0.9572664499282837 
2020-10-24 21:14:22.997998 / saving best-val-loss model 
2020-10-24 21:14:24.484654 / Iteration 1700: 0.5934666991233826 0.42264699935913086 
2020-10-24 21:14:24.533935 / Iteration 1700 valid loss 0.9564588069915771 
2020-10-24 21:14:24.537712 / saving best-val-loss model 
2020-10-24 21:14:26.077467 / Iteration 1800: 0.5173093676567078 0.44769594073295593 
2020-10-24 21:14:26.133958 / Iteration 1800 valid loss 0.9554276466369629 
2020-10-24 21:14:26.138319 / saving best-val-loss model 
2020-10-24 21:14:27.626225 / Iteration 1900: 0.6000465154647827 0.47757336497306824 
2020-10-24 21:14:27.682179 / Iteration 1900 valid loss 0.9542483687400818 
2020-10-24 21:14:27.686492 / saving best-val-loss model 
2020-10-24 21:14:29.149557 / Iteration 2000: 0.5355685353279114 0.44066739082336426 
2020-10-24 21:14:29.204622 / Iteration 2000 valid loss 0.9532235264778137 
2020-10-24 21:14:29.209167 / saving best-val-loss model 
2020-10-24 21:14:31.058393 / Iteration 2100: 0.6130767464637756 0.44099318981170654 
2020-10-24 21:14:31.109251 / Iteration 2100 valid loss 0.9526529312133789 
2020-10-24 21:14:31.113819 / saving best-val-loss model 
2020-10-24 21:14:32.733790 / Iteration 2200: 0.5383235216140747 0.4350307285785675 
2020-10-24 21:14:32.790159 / Iteration 2200 valid loss 0.9515856504440308 
2020-10-24 21:14:32.795216 / saving best-val-loss model 
2020-10-24 21:14:34.426736 / Iteration 2300: 0.5715407729148865 0.4347572922706604 
2020-10-24 21:14:34.473401 / Iteration 2300 valid loss 0.9508146047592163 
2020-10-24 21:14:34.478217 / saving best-val-loss model 
2020-10-24 21:14:35.998572 / Iteration 2400: 0.5477190613746643 0.3900469243526459 
2020-10-24 21:14:36.052702 / Iteration 2400 valid loss 0.9495372772216797 
2020-10-24 21:14:36.056353 / saving best-val-loss model 
2020-10-24 21:14:37.530554 / Iteration 2500: 0.5795893669128418 0.4140223264694214 
2020-10-24 21:14:37.583963 / Iteration 2500 valid loss 0.9483055472373962 
2020-10-24 21:14:37.588006 / saving best-val-loss model 
2020-10-24 21:14:39.100030 / Iteration 2600: 0.5102839469909668 0.42125439643859863 
2020-10-24 21:14:39.156268 / Iteration 2600 valid loss 0.947108805179596 
2020-10-24 21:14:39.160691 / saving best-val-loss model 
2020-10-24 21:14:40.577637 / Iteration 2700: 0.5357969999313354 0.41136103868484497 
2020-10-24 21:14:40.645438 / Iteration 2700 valid loss 0.9463569521903992 
2020-10-24 21:14:40.649971 / saving best-val-loss model 
2020-10-24 21:14:42.170834 / Iteration 2800: 0.6012051105499268 0.4234890937805176 
2020-10-24 21:14:42.225630 / Iteration 2800 valid loss 0.9451248049736023 
2020-10-24 21:14:42.230053 / saving best-val-loss model 
2020-10-24 21:14:43.667692 / Iteration 2900: 0.5583468079566956 0.38519906997680664 
2020-10-24 21:14:43.718437 / Iteration 2900 valid loss 0.9435156583786011 
2020-10-24 21:14:43.722856 / saving best-val-loss model 
2020-10-24 21:14:45.244248 / Iteration 3000: 0.4640539884567261 0.4021132290363312 
2020-10-24 21:14:45.309788 / Iteration 3000 valid loss 0.9421754479408264 
2020-10-24 21:14:45.314347 / saving best-val-loss model 
2020-10-24 21:14:47.124506 / Iteration 3100: 0.5382254719734192 0.44669365882873535 
2020-10-24 21:14:47.179166 / Iteration 3100 valid loss 0.9413319826126099 
2020-10-24 21:14:47.184406 / saving best-val-loss model 
2020-10-24 21:14:48.678838 / Iteration 3200: 0.5455822944641113 0.4505009651184082 
2020-10-24 21:14:48.725807 / Iteration 3200 valid loss 0.9390688538551331 
2020-10-24 21:14:48.730285 / saving best-val-loss model 
2020-10-24 21:14:50.305992 / Iteration 3300: 0.5859670639038086 0.41966307163238525 
2020-10-24 21:14:50.367633 / Iteration 3300 valid loss 0.9380452632904053 
2020-10-24 21:14:50.372554 / saving best-val-loss model 
2020-10-24 21:14:51.865337 / Iteration 3400: 0.5744635462760925 0.34996700286865234 
2020-10-24 21:14:51.914100 / Iteration 3400 valid loss 0.9365864992141724 
2020-10-24 21:14:51.918384 / saving best-val-loss model 
2020-10-24 21:14:53.337436 / Iteration 3500: 0.5892720818519592 0.39794567227363586 
2020-10-24 21:14:53.392725 / Iteration 3500 valid loss 0.9346375465393066 
2020-10-24 21:14:53.397416 / saving best-val-loss model 
2020-10-24 21:14:55.127514 / Iteration 3600: 0.7000561952590942 0.3808707594871521 
2020-10-24 21:14:55.187450 / Iteration 3600 valid loss 0.9329907298088074 
2020-10-24 21:14:55.191959 / saving best-val-loss model 
2020-10-24 21:14:56.722280 / Iteration 3700: 0.5602676868438721 0.4226054847240448 
2020-10-24 21:14:56.779825 / Iteration 3700 valid loss 0.931715190410614 
2020-10-24 21:14:56.788837 / saving best-val-loss model 
2020-10-24 21:14:58.382040 / Iteration 3800: 0.5367177724838257 0.3659386932849884 
2020-10-24 21:14:58.429524 / Iteration 3800 valid loss 0.9308478832244873 
2020-10-24 21:14:58.434198 / saving best-val-loss model 
2020-10-24 21:15:00.005675 / Iteration 3900: 0.5261778831481934 0.406674325466156 
2020-10-24 21:15:00.055869 / Iteration 3900 valid loss 0.928558886051178 
2020-10-24 21:15:00.060302 / saving best-val-loss model 
2020-10-24 21:15:01.581440 / Iteration 4000: 0.5702022314071655 0.43791571259498596 
2020-10-24 21:15:01.637691 / Iteration 4000 valid loss 0.9282870292663574 
2020-10-24 21:15:01.641865 / saving best-val-loss model 
2020-10-24 21:15:03.391980 / Iteration 4100: 0.6249168515205383 0.34314700961112976 
2020-10-24 21:15:03.450066 / Iteration 4100 valid loss 0.9273266792297363 
2020-10-24 21:15:03.454730 / saving best-val-loss model 
2020-10-24 21:15:05.126833 / Iteration 4200: 0.5066534876823425 0.3714379668235779 
2020-10-24 21:15:05.171407 / Iteration 4200 valid loss 0.9259868860244751 
2020-10-24 21:15:05.183886 / saving best-val-loss model 
2020-10-24 21:15:06.614948 / Iteration 4300: 0.5074361562728882 0.36314448714256287 
2020-10-24 21:15:06.658204 / Iteration 4300 valid loss 0.9255374073982239 
2020-10-24 21:15:06.662488 / saving best-val-loss model 
2020-10-24 21:15:08.133835 / Iteration 4400: 0.58323073387146 0.390816867351532 
2020-10-24 21:15:08.175864 / Iteration 4400 valid loss 0.9245191812515259 
2020-10-24 21:15:08.191213 / saving best-val-loss model 
2020-10-24 21:15:09.840288 / Iteration 4500: 0.5614161491394043 0.36662957072257996 
2020-10-24 21:15:09.895714 / Iteration 4500 valid loss 0.9239879250526428 
2020-10-24 21:15:09.900415 / saving best-val-loss model 
2020-10-24 21:15:11.426807 / Iteration 4600: 0.5557208061218262 0.36629897356033325 
2020-10-24 21:15:11.483797 / Iteration 4600 valid loss 0.9237934947013855 
2020-10-24 21:15:11.494550 / saving best-val-loss model 
2020-10-24 21:15:13.015156 / Iteration 4700: 0.5756434798240662 0.38927412033081055 
2020-10-24 21:15:13.067622 / Iteration 4700 valid loss 0.9237585067749023 
2020-10-24 21:15:13.080693 / saving best-val-loss model 
2020-10-24 21:15:14.652513 / Iteration 4800: 0.5711660981178284 0.3318711519241333 
2020-10-24 21:15:14.698768 / Iteration 4800 valid loss 0.9232980608940125 
2020-10-24 21:15:14.703214 / saving best-val-loss model 
2020-10-24 21:15:16.243217 / Iteration 4900: 0.6151684522628784 0.36493414640426636 
2020-10-24 21:15:16.293558 / Iteration 4900 valid loss 0.9233622550964355 
2020-10-24 21:15:17.852023 / Iteration 5000: 0.5637068748474121 0.4310355484485626 
2020-10-24 21:15:17.909031 / Iteration 5000 valid loss 0.9228740930557251 
2020-10-24 21:15:17.914668 / saving best-val-loss model 
2020-10-24 21:15:19.762316 / Iteration 5100: 0.561194896697998 0.3791066110134125 
2020-10-24 21:15:19.818408 / Iteration 5100 valid loss 0.922432541847229 
2020-10-24 21:15:19.823257 / saving best-val-loss model 
2020-10-24 21:15:21.383431 / Iteration 5200: 0.5537164211273193 0.36130303144454956 
2020-10-24 21:15:21.432583 / Iteration 5200 valid loss 0.9226570725440979 
2020-10-24 21:15:22.978871 / Iteration 5300: 0.569849967956543 0.3825480043888092 
2020-10-24 21:15:23.042680 / Iteration 5300 valid loss 0.9224056601524353 
2020-10-24 21:15:23.047522 / saving best-val-loss model 
2020-10-24 21:15:24.616493 / Iteration 5400: 0.6051885485649109 0.3337824046611786 
2020-10-24 21:15:24.677353 / Iteration 5400 valid loss 0.9215499758720398 
2020-10-24 21:15:24.682535 / saving best-val-loss model 
2020-10-24 21:15:26.209819 / Iteration 5500: 0.5568195581436157 0.387332022190094 
2020-10-24 21:15:26.259424 / Iteration 5500 valid loss 0.9214853644371033 
2020-10-24 21:15:26.264471 / saving best-val-loss model 
2020-10-24 21:15:27.938299 / Iteration 5600: 0.5674592852592468 0.2994181215763092 
2020-10-24 21:15:27.985618 / Iteration 5600 valid loss 0.9212705492973328 
2020-10-24 21:15:27.990578 / saving best-val-loss model 
2020-10-24 21:15:29.543970 / Iteration 5700: 0.507831335067749 0.4087289571762085 
2020-10-24 21:15:29.601634 / Iteration 5700 valid loss 0.921302855014801 
2020-10-24 21:15:31.006875 / Iteration 5800: 0.5851070880889893 0.3649956285953522 
2020-10-24 21:15:31.054714 / Iteration 5800 valid loss 0.9205829501152039 
2020-10-24 21:15:31.059152 / saving best-val-loss model 
2020-10-24 21:15:32.611202 / Iteration 5900: 0.6197501420974731 0.3418685495853424 
2020-10-24 21:15:32.663017 / Iteration 5900 valid loss 0.9209368228912354 
2020-10-24 21:15:34.275471 / Iteration 6000: 0.5456181764602661 0.4491475224494934 
2020-10-24 21:15:34.341098 / Iteration 6000 valid loss 0.9212071895599365 
2020-10-24 21:15:36.584868 / Iteration 6100: 0.5898322463035583 0.313499391078949 
2020-10-24 21:15:36.649482 / Iteration 6100 valid loss 0.9206538796424866 
2020-10-24 21:15:38.539430 / Iteration 6200: 0.6306771636009216 0.4311249852180481 
2020-10-24 21:15:38.598899 / Iteration 6200 valid loss 0.9202585220336914 
2020-10-24 21:15:38.604127 / saving best-val-loss model 
2020-10-24 21:15:40.458072 / Iteration 6300: 0.5739135146141052 0.39401137828826904 
2020-10-24 21:15:40.529996 / Iteration 6300 valid loss 0.9205777645111084 
2020-10-24 21:15:42.356652 / Iteration 6400: 0.5604488849639893 0.35295623540878296 
2020-10-24 21:15:42.431144 / Iteration 6400 valid loss 0.9210834503173828 
2020-10-24 21:15:44.305884 / Iteration 6500: 0.575347900390625 0.3668917417526245 
2020-10-24 21:15:44.377457 / Iteration 6500 valid loss 0.9198639988899231 
2020-10-24 21:15:44.382949 / saving best-val-loss model 
2020-10-24 21:15:46.254555 / Iteration 6600: 0.5092151165008545 0.2808915972709656 
2020-10-24 21:15:46.320616 / Iteration 6600 valid loss 0.9201657176017761 
2020-10-24 21:15:48.140577 / Iteration 6700: 0.5446245074272156 0.38206684589385986 
2020-10-24 21:15:48.205335 / Iteration 6700 valid loss 0.9204782247543335 
2020-10-24 21:15:50.052688 / Iteration 6800: 0.537203311920166 0.35538268089294434 
2020-10-24 21:15:50.111006 / Iteration 6800 valid loss 0.920220136642456 
2020-10-24 21:15:51.963594 / Iteration 6900: 0.5899896621704102 0.3875243663787842 
2020-10-24 21:15:52.029550 / Iteration 6900 valid loss 0.919373095035553 
2020-10-24 21:15:52.040682 / saving best-val-loss model 
2020-10-24 21:15:53.941535 / Iteration 7000: 0.509291410446167 0.3472563624382019 
2020-10-24 21:15:54.025408 / Iteration 7000 valid loss 0.9198966026306152 
2020-10-24 21:15:56.321994 / Iteration 7100: 0.5391486287117004 0.41260120272636414 
2020-10-24 21:15:56.381961 / Iteration 7100 valid loss 0.920059859752655 
2020-10-24 21:15:58.222133 / Iteration 7200: 0.6074111461639404 0.35705992579460144 
2020-10-24 21:15:58.303646 / Iteration 7200 valid loss 0.9197710752487183 
2020-10-24 21:16:00.156775 / Iteration 7300: 0.5078979730606079 0.38283225893974304 
2020-10-24 21:16:00.218400 / Iteration 7300 valid loss 0.9194508194923401 
2020-10-24 21:16:02.026952 / Iteration 7400: 0.5689129829406738 0.34543153643608093 
2020-10-24 21:16:02.090263 / Iteration 7400 valid loss 0.9192440509796143 
2020-10-24 21:16:02.095854 / saving best-val-loss model 
2020-10-24 21:16:03.927247 / Iteration 7500: 0.5469342470169067 0.36887994408607483 
2020-10-24 21:16:03.991913 / Iteration 7500 valid loss 0.919201672077179 
2020-10-24 21:16:03.999334 / saving best-val-loss model 
2020-10-24 21:16:05.827957 / Iteration 7600: 0.540219247341156 0.3797030746936798 
2020-10-24 21:16:05.891288 / Iteration 7600 valid loss 0.9193205833435059 
2020-10-24 21:16:07.763934 / Iteration 7700: 0.5851625800132751 0.35433122515678406 
2020-10-24 21:16:07.836685 / Iteration 7700 valid loss 0.9190945029258728 
2020-10-24 21:16:07.842138 / saving best-val-loss model 
2020-10-24 21:16:09.726095 / Iteration 7800: 0.5973525047302246 0.410182923078537 
2020-10-24 21:16:09.790441 / Iteration 7800 valid loss 0.91941237449646 
2020-10-24 21:16:11.645542 / Iteration 7900: 0.548162043094635 0.34962746500968933 
2020-10-24 21:16:11.714375 / Iteration 7900 valid loss 0.9186691045761108 
2020-10-24 21:16:11.724573 / saving best-val-loss model 
2020-10-24 21:16:13.639429 / Iteration 8000: 0.5929776430130005 0.3736071288585663 
2020-10-24 21:16:13.710335 / Iteration 8000 valid loss 0.919159471988678 
2020-10-24 21:16:16.031689 / Iteration 8100: 0.5738420486450195 0.36112895607948303 
2020-10-24 21:16:16.099959 / Iteration 8100 valid loss 0.9188352823257446 
2020-10-24 21:16:17.908290 / Iteration 8200: 0.5304327011108398 0.4259636700153351 
2020-10-24 21:16:17.984003 / Iteration 8200 valid loss 0.9187093377113342 
2020-10-24 21:16:19.836621 / Iteration 8300: 0.5843749642372131 0.4411770701408386 
2020-10-24 21:16:19.903673 / Iteration 8300 valid loss 0.9193548560142517 
2020-10-24 21:16:21.743358 / Iteration 8400: 0.5863533616065979 0.25683942437171936 
2020-10-24 21:16:21.809668 / Iteration 8400 valid loss 0.9188424944877625 
2020-10-24 21:16:23.608382 / Iteration 8500: 0.509326696395874 0.33985018730163574 
2020-10-24 21:16:23.667824 / Iteration 8500 valid loss 0.918205738067627 
2020-10-24 21:16:23.677364 / saving best-val-loss model 
2020-10-24 21:16:25.540899 / Iteration 8600: 0.5140252113342285 0.33158570528030396 
2020-10-24 21:16:25.625484 / Iteration 8600 valid loss 0.9187315106391907 
2020-10-24 21:16:27.448611 / Iteration 8700: 0.5332043766975403 0.3153243660926819 
2020-10-24 21:16:27.514643 / Iteration 8700 valid loss 0.9185401797294617 
2020-10-24 21:16:29.296728 / Iteration 8800: 0.594518780708313 0.34503987431526184 
2020-10-24 21:16:29.365611 / Iteration 8800 valid loss 0.9179947376251221 
2020-10-24 21:16:29.371166 / saving best-val-loss model 
2020-10-24 21:16:31.257464 / Iteration 8900: 0.5296692252159119 0.33387523889541626 
2020-10-24 21:16:31.323973 / Iteration 8900 valid loss 0.9183416962623596 
2020-10-24 21:16:33.156945 / Iteration 9000: 0.5677297115325928 0.4564952552318573 
2020-10-24 21:16:33.228124 / Iteration 9000 valid loss 0.9185459017753601 
2020-10-24 21:16:35.550551 / Iteration 9100: 0.5777640342712402 0.3684104084968567 
2020-10-24 21:16:35.615531 / Iteration 9100 valid loss 0.9191934466362 
2020-10-24 21:16:37.413174 / Iteration 9200: 0.5770366191864014 0.3574693202972412 
2020-10-24 21:16:37.471784 / Iteration 9200 valid loss 0.9182960391044617 
2020-10-24 21:16:39.263199 / Iteration 9300: 0.5462552309036255 0.33628663420677185 
2020-10-24 21:16:39.325188 / Iteration 9300 valid loss 0.9178745150566101 
2020-10-24 21:16:39.331653 / saving best-val-loss model 
2020-10-24 21:16:41.223785 / Iteration 9400: 0.5580555200576782 0.39786893129348755 
2020-10-24 21:16:41.291658 / Iteration 9400 valid loss 0.9187751412391663 
2020-10-24 21:16:43.132615 / Iteration 9500: 0.6041332483291626 0.43077853322029114 
2020-10-24 21:16:43.200639 / Iteration 9500 valid loss 0.9180476069450378 
2020-10-24 21:16:45.001723 / Iteration 9600: 0.5643648505210876 0.3370779752731323 
2020-10-24 21:16:45.065171 / Iteration 9600 valid loss 0.9180588126182556 
2020-10-24 21:16:46.875175 / Iteration 9700: 0.5473830103874207 0.3488547205924988 
2020-10-24 21:16:46.950524 / Iteration 9700 valid loss 0.9181397557258606 
2020-10-24 21:16:48.826336 / Iteration 9800: 0.5636235475540161 0.35245487093925476 
2020-10-24 21:16:48.899613 / Iteration 9800 valid loss 0.9182788133621216 
2020-10-24 21:16:50.781577 / Iteration 9900: 0.5161603093147278 0.3307242691516876 
2020-10-24 21:16:50.850528 / Iteration 9900 valid loss 0.9181079268455505 
2020-10-24 21:16:52.698269 / Iteration 10000: 0.5608868598937988 0.38384491205215454 
2020-10-24 21:16:52.761304 / Iteration 10000 valid loss 0.9186623692512512 
2020-10-24 21:17:11.652322 / Iteration 10100: 0.5568347573280334 0.4224485158920288 
2020-10-24 21:17:11.717029 / Iteration 10100 valid loss 0.9176269173622131 
2020-10-24 21:17:11.722679 / saving best-val-loss model 
2020-10-24 21:17:13.570259 / Iteration 10200: 0.582389235496521 0.286022424697876 
2020-10-24 21:17:13.633501 / Iteration 10200 valid loss 0.918068528175354 
2020-10-24 21:17:15.508118 / Iteration 10300: 0.5941935181617737 0.3911891281604767 
2020-10-24 21:17:15.578374 / Iteration 10300 valid loss 0.9180678129196167 
2020-10-24 21:17:17.404633 / Iteration 10400: 0.5566472411155701 0.3562352955341339 
2020-10-24 21:17:17.466838 / Iteration 10400 valid loss 0.9171692728996277 
2020-10-24 21:17:17.475346 / saving best-val-loss model 
2020-10-24 21:17:19.318176 / Iteration 10500: 0.566182017326355 0.38668423891067505 
2020-10-24 21:17:19.376421 / Iteration 10500 valid loss 0.9174108505249023 
2020-10-24 21:17:21.286518 / Iteration 10600: 0.5574012398719788 0.45383045077323914 
2020-10-24 21:17:21.349678 / Iteration 10600 valid loss 0.9177075028419495 
2020-10-24 21:17:23.236373 / Iteration 10700: 0.575721025466919 0.33049270510673523 
2020-10-24 21:17:23.307042 / Iteration 10700 valid loss 0.9178373217582703 
2020-10-24 21:17:25.181104 / Iteration 10800: 0.5430502891540527 0.39130550622940063 
2020-10-24 21:17:25.245413 / Iteration 10800 valid loss 0.9172704815864563 
2020-10-24 21:17:27.125472 / Iteration 10900: 0.5034554600715637 0.3871658444404602 
2020-10-24 21:17:27.200478 / Iteration 10900 valid loss 0.9171324968338013 
2020-10-24 21:17:27.206317 / saving best-val-loss model 
2020-10-24 21:17:29.114769 / Iteration 11000: 0.5722466111183167 0.4029857814311981 
2020-10-24 21:17:29.199311 / Iteration 11000 valid loss 0.9177877902984619 
2020-10-24 21:17:31.543165 / Iteration 11100: 0.5619045495986938 0.3726058006286621 
2020-10-24 21:17:31.610010 / Iteration 11100 valid loss 0.9164154529571533 
2020-10-24 21:17:31.615497 / saving best-val-loss model 
2020-10-24 21:17:33.492309 / Iteration 11200: 0.5687592625617981 0.3534811735153198 
2020-10-24 21:17:33.560915 / Iteration 11200 valid loss 0.9175155162811279 
2020-10-24 21:17:35.373025 / Iteration 11300: 0.5846673846244812 0.40227651596069336 
2020-10-24 21:17:35.445679 / Iteration 11300 valid loss 0.9169967770576477 
2020-10-24 21:17:37.266103 / Iteration 11400: 0.5884831547737122 0.35717862844467163 
2020-10-24 21:17:37.328258 / Iteration 11400 valid loss 0.9174960851669312 
2020-10-24 21:17:39.203135 / Iteration 11500: 0.5037590265274048 0.3834482729434967 
2020-10-24 21:17:39.275813 / Iteration 11500 valid loss 0.9163027405738831 
2020-10-24 21:17:39.281478 / saving best-val-loss model 
2020-10-24 21:17:41.166492 / Iteration 11600: 0.5315909385681152 0.3833554685115814 
2020-10-24 21:17:41.236463 / Iteration 11600 valid loss 0.9164731502532959 
2020-10-24 21:17:43.114891 / Iteration 11700: 0.5871838331222534 0.3724057078361511 
2020-10-24 21:17:43.181867 / Iteration 11700 valid loss 0.9168067574501038 
2020-10-24 21:17:45.061658 / Iteration 11800: 0.581739068031311 0.4157312512397766 
2020-10-24 21:17:45.127226 / Iteration 11800 valid loss 0.9174596071243286 
2020-10-24 21:17:46.958027 / Iteration 11900: 0.5368883609771729 0.41382813453674316 
2020-10-24 21:17:47.006817 / Iteration 11900 valid loss 0.9162830114364624 
2020-10-24 21:17:47.012343 / saving best-val-loss model 
2020-10-24 21:17:48.872570 / Iteration 12000: 0.653466522693634 0.3605389893054962 
2020-10-24 21:17:48.935330 / Iteration 12000 valid loss 0.9169686436653137 
2020-10-24 21:17:51.359634 / Iteration 12100: 0.5579600930213928 0.4075016975402832 
2020-10-24 21:17:51.428710 / Iteration 12100 valid loss 0.9165011644363403 
2020-10-24 21:17:53.311644 / Iteration 12200: 0.5247319936752319 0.35142818093299866 
2020-10-24 21:17:53.389664 / Iteration 12200 valid loss 0.9169341921806335 
2020-10-24 21:17:55.238699 / Iteration 12300: 0.6043984293937683 0.3894575536251068 
2020-10-24 21:17:55.306048 / Iteration 12300 valid loss 0.9159312844276428 
2020-10-24 21:17:55.318369 / saving best-val-loss model 
2020-10-24 21:17:57.167610 / Iteration 12400: 0.5519022941589355 0.33799195289611816 
2020-10-24 21:17:57.234299 / Iteration 12400 valid loss 0.9169130921363831 
2020-10-24 21:17:59.034717 / Iteration 12500: 0.5095288157463074 0.3871922194957733 
2020-10-24 21:17:59.088717 / Iteration 12500 valid loss 0.9167914390563965 
2020-10-24 21:18:00.915149 / Iteration 12600: 0.5134299993515015 0.3794313073158264 
2020-10-24 21:18:00.988115 / Iteration 12600 valid loss 0.9166162014007568 
2020-10-24 21:18:02.850249 / Iteration 12700: 0.5630643963813782 0.3838568329811096 
2020-10-24 21:18:02.905456 / Iteration 12700 valid loss 0.9161027669906616 
2020-10-24 21:18:04.775243 / Iteration 12800: 0.5745441317558289 0.4150654673576355 
2020-10-24 21:18:04.848772 / Iteration 12800 valid loss 0.9161098599433899 
2020-10-24 21:18:06.815264 / Iteration 12900: 0.5361510515213013 0.35836681723594666 
2020-10-24 21:18:06.878176 / Iteration 12900 valid loss 0.9158326983451843 
2020-10-24 21:18:06.883517 / saving best-val-loss model 
2020-10-24 21:18:08.833666 / Iteration 13000: 0.5869182348251343 0.44141656160354614 
2020-10-24 21:18:08.902209 / Iteration 13000 valid loss 0.9162936806678772 
2020-10-24 21:18:11.182255 / Iteration 13100: 0.5875502824783325 0.4342126250267029 
2020-10-24 21:18:11.256709 / Iteration 13100 valid loss 0.915706992149353 
2020-10-24 21:18:11.262212 / saving best-val-loss model 
2020-10-24 21:18:13.185976 / Iteration 13200: 0.5377083420753479 0.30375030636787415 
2020-10-24 21:18:13.260295 / Iteration 13200 valid loss 0.9163269996643066 
2020-10-24 21:18:15.200464 / Iteration 13300: 0.5750919580459595 0.42742615938186646 
2020-10-24 21:18:15.265963 / Iteration 13300 valid loss 0.9161738753318787 
2020-10-24 21:18:17.079786 / Iteration 13400: 0.5516228079795837 0.4040159583091736 
2020-10-24 21:18:17.141784 / Iteration 13400 valid loss 0.9157721996307373 
2020-10-24 21:18:19.072014 / Iteration 13500: 0.5544334053993225 0.3560868799686432 
2020-10-24 21:18:19.146289 / Iteration 13500 valid loss 0.9156849980354309 
2020-10-24 21:18:19.152623 / saving best-val-loss model 
2020-10-24 21:18:21.058734 / Iteration 13600: 0.5137186050415039 0.37725934386253357 
2020-10-24 21:18:21.141383 / Iteration 13600 valid loss 0.9156064987182617 
2020-10-24 21:18:21.149213 / saving best-val-loss model 
2020-10-24 21:18:23.090845 / Iteration 13700: 0.5664842128753662 0.35009485483169556 
2020-10-24 21:18:23.162800 / Iteration 13700 valid loss 0.9159000515937805 
2020-10-24 21:18:25.113310 / Iteration 13800: 0.6751981377601624 0.4270681142807007 
2020-10-24 21:18:25.187096 / Iteration 13800 valid loss 0.915998637676239 
2020-10-24 21:18:27.085444 / Iteration 13900: 0.5717728137969971 0.39830341935157776 
2020-10-24 21:18:27.175631 / Iteration 13900 valid loss 0.9153997898101807 
2020-10-24 21:18:27.186919 / saving best-val-loss model 
2020-10-24 21:18:29.105421 / Iteration 14000: 0.5467702150344849 0.4405289888381958 
2020-10-24 21:18:29.179992 / Iteration 14000 valid loss 0.9151149988174438 
2020-10-24 21:18:29.191376 / saving best-val-loss model 
2020-10-24 21:18:31.448254 / Iteration 14100: 0.5553191304206848 0.4394661486148834 
2020-10-24 21:18:31.512680 / Iteration 14100 valid loss 0.9161325097084045 
2020-10-24 21:18:33.368994 / Iteration 14200: 0.5285919904708862 0.3419060707092285 
2020-10-24 21:18:33.432951 / Iteration 14200 valid loss 0.9158200025558472 
2020-10-24 21:18:35.316095 / Iteration 14300: 0.5688636302947998 0.3698309659957886 
2020-10-24 21:18:35.383598 / Iteration 14300 valid loss 0.915520429611206 
2020-10-24 21:18:37.355682 / Iteration 14400: 0.5887182950973511 0.4460311532020569 
2020-10-24 21:18:37.429471 / Iteration 14400 valid loss 0.9149570465087891 
2020-10-24 21:18:37.438010 / saving best-val-loss model 
2020-10-24 21:18:39.375586 / Iteration 14500: 0.5585934519767761 0.42209142446517944 
2020-10-24 21:18:39.441504 / Iteration 14500 valid loss 0.9153580665588379 
2020-10-24 21:18:41.434226 / Iteration 14600: 0.5714690685272217 0.41970327496528625 
2020-10-24 21:18:41.521547 / Iteration 14600 valid loss 0.9156122207641602 
2020-10-24 21:18:43.375181 / Iteration 14700: 0.5367051362991333 0.31867823004722595 
2020-10-24 21:18:43.444527 / Iteration 14700 valid loss 0.9150238633155823 
2020-10-24 21:18:45.337448 / Iteration 14800: 0.5574024319648743 0.38862282037734985 
2020-10-24 21:18:45.396600 / Iteration 14800 valid loss 0.9153640270233154 
2020-10-24 21:18:47.357719 / Iteration 14900: 0.5601285696029663 0.3654269576072693 
2020-10-24 21:18:47.412427 / Iteration 14900 valid loss 0.9151949882507324 
2020-10-24 21:18:49.313474 / Iteration 15000: 0.5285405516624451 0.449985146522522 
2020-10-24 21:18:49.385028 / Iteration 15000 valid loss 0.9160651564598083 
2020-10-24 21:18:51.453242 / Iteration 15100: 0.5532640218734741 0.3661891520023346 
2020-10-24 21:18:51.516932 / Iteration 15100 valid loss 0.915558397769928 
2020-10-24 21:18:53.264321 / Iteration 15200: 0.4965026378631592 0.3291029632091522 
2020-10-24 21:18:53.326832 / Iteration 15200 valid loss 0.916296660900116 
2020-10-24 21:18:55.117566 / Iteration 15300: 0.5578235387802124 0.3219638168811798 
2020-10-24 21:18:55.179766 / Iteration 15300 valid loss 0.9154447317123413 
2020-10-24 21:18:56.943396 / Iteration 15400: 0.5490504503250122 0.41115856170654297 
2020-10-24 21:18:57.005293 / Iteration 15400 valid loss 0.9150557518005371 
2020-10-24 21:18:58.578548 / Iteration 15500: 0.5559525489807129 0.3079105317592621 
2020-10-24 21:18:58.617463 / Iteration 15500 valid loss 0.91541588306427 
2020-10-24 21:19:00.013325 / Iteration 15600: 0.5878840088844299 0.4035258889198303 
2020-10-24 21:19:00.073870 / Iteration 15600 valid loss 0.9149543642997742 
2020-10-24 21:19:00.078557 / saving best-val-loss model 
2020-10-24 21:19:01.240275 / Iteration 15700: 0.564895510673523 0.4190136194229126 
2020-10-24 21:19:01.282655 / Iteration 15700 valid loss 0.9155306220054626 
2020-10-24 21:19:02.510923 / Iteration 15800: 0.5812188386917114 0.3966241478919983 
2020-10-24 21:19:02.566069 / Iteration 15800 valid loss 0.9156606197357178 
2020-10-24 21:19:03.910543 / Iteration 15900: 0.5623180866241455 0.41074180603027344 
2020-10-24 21:19:03.948946 / Iteration 15900 valid loss 0.9159592986106873 
2020-10-24 21:19:05.374593 / Iteration 16000: 0.5402065515518188 0.33874785900115967 
2020-10-24 21:19:05.426598 / Iteration 16000 valid loss 0.915136992931366 
2020-10-24 21:19:07.576857 / Iteration 16100: 0.5739949345588684 0.3950565457344055 
2020-10-24 21:19:07.637924 / Iteration 16100 valid loss 0.9150046110153198 
2020-10-24 21:19:09.173656 / Iteration 16200: 0.5910476446151733 0.3713175356388092 
2020-10-24 21:19:09.233678 / Iteration 16200 valid loss 0.9154187440872192 
2020-10-24 21:19:10.801859 / Iteration 16300: 0.5427400469779968 0.3449857234954834 
2020-10-24 21:19:10.852439 / Iteration 16300 valid loss 0.9160392880439758 
2020-10-24 21:19:12.440002 / Iteration 16400: 0.5646699666976929 0.3624155521392822 
2020-10-24 21:19:12.492302 / Iteration 16400 valid loss 0.9153146147727966 
2020-10-24 21:19:14.034972 / Iteration 16500: 0.496651828289032 0.33456623554229736 
2020-10-24 21:19:14.083404 / Iteration 16500 valid loss 0.9155625700950623 
2020-10-24 21:19:15.716461 / Iteration 16600: 0.5535666346549988 0.34412682056427 
2020-10-24 21:19:15.772150 / Iteration 16600 valid loss 0.9152847528457642 
2020-10-24 21:19:17.347643 / Iteration 16700: 0.6380525827407837 0.39551568031311035 
2020-10-24 21:19:17.403231 / Iteration 16700 valid loss 0.9151120185852051 
2020-10-24 21:19:18.935512 / Iteration 16800: 0.5719226002693176 0.3013349771499634 
2020-10-24 21:19:18.992395 / Iteration 16800 valid loss 0.915224015712738 
2020-10-24 21:19:20.511766 / Iteration 16900: 0.5675278902053833 0.37033751606941223 
2020-10-24 21:19:20.578646 / Iteration 16900 valid loss 0.9151749014854431 
2020-10-24 21:19:22.132319 / Iteration 17000: 0.5621737837791443 0.3737373948097229 
2020-10-24 21:19:22.203347 / Iteration 17000 valid loss 0.9149019122123718 
2020-10-24 21:19:22.208255 / saving best-val-loss model 
2020-10-24 21:19:24.148064 / Iteration 17100: 0.5597209930419922 0.3839288651943207 
2020-10-24 21:19:24.201035 / Iteration 17100 valid loss 0.915170431137085 
2020-10-24 21:19:25.805424 / Iteration 17200: 0.5930113792419434 0.39037054777145386 
2020-10-24 21:19:25.871609 / Iteration 17200 valid loss 0.9152941107749939 
2020-10-24 21:19:27.419405 / Iteration 17300: 0.5688914656639099 0.3969506323337555 
2020-10-24 21:19:27.461205 / Iteration 17300 valid loss 0.9152787327766418 
2020-10-24 21:19:28.997305 / Iteration 17400: 0.5335386991500854 0.3801274597644806 
2020-10-24 21:19:29.058852 / Iteration 17400 valid loss 0.9157080054283142 
2020-10-24 21:19:30.723526 / Iteration 17500: 0.5370948910713196 0.37667426466941833 
2020-10-24 21:19:30.763893 / Iteration 17500 valid loss 0.9162865877151489 
2020-10-24 21:19:32.363641 / Iteration 17600: 0.5833854079246521 0.369170606136322 
2020-10-24 21:19:32.422099 / Iteration 17600 valid loss 0.916283905506134 
2020-10-24 21:19:33.847640 / Iteration 17700: 0.5583171844482422 0.4078526496887207 
2020-10-24 21:19:33.887621 / Iteration 17700 valid loss 0.9149883389472961 
2020-10-24 21:19:35.422142 / Iteration 17800: 0.5541293621063232 0.38637930154800415 
2020-10-24 21:19:35.479904 / Iteration 17800 valid loss 0.9156551957130432 
2020-10-24 21:19:36.978606 / Iteration 17900: 0.4749875068664551 0.33054429292678833 
2020-10-24 21:19:37.020547 / Iteration 17900 valid loss 0.9165529012680054 
2020-10-24 21:19:38.605163 / Iteration 18000: 0.6148139238357544 0.29591840505599976 
2020-10-24 21:19:38.667253 / Iteration 18000 valid loss 0.9157599806785583 
2020-10-24 21:19:40.915446 / Iteration 18100: 0.5793538093566895 0.38848334550857544 
2020-10-24 21:19:40.968231 / Iteration 18100 valid loss 0.9157681465148926 
2020-10-24 21:19:42.570336 / Iteration 18200: 0.6195496916770935 0.38228097558021545 
2020-10-24 21:19:42.617385 / Iteration 18200 valid loss 0.9157409071922302 
2020-10-24 21:19:44.141130 / Iteration 18300: 0.5580078363418579 0.4379936158657074 
2020-10-24 21:19:44.182683 / Iteration 18300 valid loss 0.9157039523124695 
2020-10-24 21:19:45.736439 / Iteration 18400: 0.5562001466751099 0.2949135899543762 
2020-10-24 21:19:45.799663 / Iteration 18400 valid loss 0.9162459373474121 
2020-10-24 21:19:47.326365 / Iteration 18500: 0.5376162528991699 0.41323214769363403 
2020-10-24 21:19:47.386250 / Iteration 18500 valid loss 0.9161030650138855 
2020-10-24 21:19:48.917234 / Iteration 18600: 0.5731244087219238 0.36644265055656433 
2020-10-24 21:19:48.970670 / Iteration 18600 valid loss 0.9160054326057434 
2020-10-24 21:19:50.518252 / Iteration 18700: 0.5506023168563843 0.3619425892829895 
2020-10-24 21:19:50.575810 / Iteration 18700 valid loss 0.9159665107727051 
2020-10-24 21:19:52.098905 / Iteration 18800: 0.5442792773246765 0.3671463131904602 
2020-10-24 21:19:52.146734 / Iteration 18800 valid loss 0.9163541197776794 
2020-10-24 21:19:53.683375 / Iteration 18900: 0.5606676340103149 0.3166903853416443 
2020-10-24 21:19:53.745862 / Iteration 18900 valid loss 0.9162877798080444 
2020-10-24 21:19:55.342711 / Iteration 19000: 0.5645180940628052 0.33045604825019836 
2020-10-24 21:19:55.387820 / Iteration 19000 valid loss 0.9157729148864746 
2020-10-24 21:19:55.819036 / early stopping criterion reached. Ending experiment. 
2020-10-24 21:20:34.834287 / OrderedDict([('nll', 0.9149019122123718), ('avg_t_pval', 0.9873588872599492), ('avg_y_pval', 0.8879821469934603), ('min_t_pval', 0.8195761539997716), ('min_y_pval', 0.3185174292595868), ('q30_t_pval', 0.9999022902323365), ('q30_y_pval', 0.8986009607551757), ('q50_t_pval', 0.9999999970560134), ('q50_y_pval', 0.9710854387110668), ('ate_exact', -0.07544508576393127), ('ate_noisy', -0.06974299054592847)]) 
